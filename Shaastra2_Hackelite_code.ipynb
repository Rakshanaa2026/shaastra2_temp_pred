{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc1GkTTcDpW_",
        "outputId": "c28936a1-0fe0-426c-95b2-cb09c9ae80b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Regressor - MAE: 1.6799, MSE: 4.5854, R²: 0.9747\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import GradientBoostingRegressor, StackingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.linear_model import SGDRegressor, ElasticNet, HuberRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor  # Ensure to install xgboost\n",
        "\n",
        "# Load datasets\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')\n",
        "sample_submission = pd.read_csv('/content/sample_submission.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "for dataset in [train_data, test_data]:\n",
        "    dataset['DATE'] = pd.to_datetime(dataset['DATE'], dayfirst=True)\n",
        "    dataset.drop(columns=['PRCP_A', 'PRCP_B', 'PRCP_C', 'Unnamed: 0', 'SNWD_A', 'SNWD_B', 'SNWD_C', 'ELEVATION_A', 'ELEVATION_B', 'ELEVATION_C'], errors='ignore', inplace=True)\n",
        "\n",
        "temp_columns = ['TMAX_A', 'TMIN_A', 'TAVG_A', 'TMAX_B', 'TMIN_B', 'TAVG_B', 'TMAX_C', 'TMIN_C', 'TAVG_C']\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "train_data[temp_columns] = imputer.fit_transform(train_data[temp_columns])\n",
        "test_data[temp_columns] = imputer.transform(test_data[temp_columns])\n",
        "\n",
        "train_data['TAVG_A'] = train_data[['TAVG_A', 'TMAX_A']].min(axis=1)\n",
        "test_data['TAVG_A'] = test_data[['TAVG_A', 'TMAX_A']].min(axis=1)\n",
        "\n",
        "# Function to extract date features\n",
        "def extract_date_features(dataset):\n",
        "    dataset['YEAR'] = dataset['DATE'].dt.year\n",
        "    dataset['MONTH'] = dataset['DATE'].dt.month\n",
        "    dataset['DAY'] = dataset['DATE'].dt.day\n",
        "    dataset['DAYOFWEEK'] = dataset['DATE'].dt.dayofweek\n",
        "    dataset['WEEKEND'] = (dataset['DAYOFWEEK'] >= 5).astype(int)\n",
        "    dataset['DAYOFYEAR'] = dataset['DATE'].dt.dayofyear\n",
        "    dataset['MONTH_DAY'] = dataset['MONTH'] * dataset['DAY']\n",
        "\n",
        "for dataset in [train_data, test_data]:\n",
        "    extract_date_features(dataset)\n",
        "\n",
        "X = train_data.drop(columns=['DATE', 'TAVG'])\n",
        "y = train_data['TAVG']\n",
        "X_test = test_data.drop(columns=['INDEX', 'DATE'])\n",
        "\n",
        "# Numeric transformer pipeline\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "X = numeric_transformer.fit_transform(X)\n",
        "X_test = numeric_transformer.transform(X_test)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Feature selection using GradientBoostingRegressor\n",
        "selection_model = GradientBoostingRegressor(random_state=0)\n",
        "selection_model.fit(X_train, y_train)\n",
        "selector = SelectFromModel(selection_model, threshold=\"mean\", prefit=True)\n",
        "\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_valid_selected = selector.transform(X_valid)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Define models with Huber loss and other models\n",
        "sgd_best = SGDRegressor(alpha=0.001, eta0=0.01, learning_rate='invscaling', loss='huber', penalty='elasticnet', max_iter=1000, tol=1e-3, random_state=0)\n",
        "mlp_best = MLPRegressor(hidden_layer_sizes=(100, 100), alpha=0.1, learning_rate_init=0.01, solver='adam', learning_rate='adaptive', max_iter=500, random_state=0)  # Adam optimizer is used here\n",
        "svr_best = SVR(C=10, epsilon=0.1, kernel='rbf')\n",
        "xgb_best = XGBRegressor(learning_rate=0.1, max_depth=3, n_estimators=200, objective='reg:squarederror', random_state=0)\n",
        "elastic_best = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=1000, tol=0.01, random_state=0)\n",
        "\n",
        "ada_best = AdaBoostRegressor(learning_rate=1.0, n_estimators=200, random_state=0)\n",
        "rf_best = RandomForestRegressor(n_estimators=200, max_depth=None, random_state=0)\n",
        "gbr_best = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, loss='huber', random_state=0)\n",
        "\n",
        "# Stacking Regressor with the models\n",
        "stacked_model = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('mlp', mlp_best),\n",
        "        ('xgb', xgb_best),\n",
        "        ('gbr', gbr_best),\n",
        "        ('rf', rf_best),\n",
        "        ('elastic', elastic_best),\n",
        "        ('huber', HuberRegressor(alpha=10, epsilon=1.5))\n",
        "    ],\n",
        "    final_estimator=SVR(C=10, epsilon=0.1, kernel='rbf')\n",
        ")\n",
        "\n",
        "# Fit the stacked model and predict\n",
        "stacked_model.fit(X_train_selected, y_train)\n",
        "y_valid_pred = stacked_model.predict(X_valid_selected)\n",
        "\n",
        "# Evaluation metrics\n",
        "mae = mean_absolute_error(y_valid, y_valid_pred)\n",
        "mse = mean_squared_error(y_valid, y_valid_pred)\n",
        "r2 = r2_score(y_valid, y_valid_pred)\n",
        "\n",
        "print(f\"Stacking Regressor - MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "# Predict on the test set and save submission\n",
        "y_test_pred = stacked_model.predict(X_test_selected)\n",
        "submission = sample_submission.copy()\n",
        "submission['TAVG'] = y_test_pred\n",
        "submission.to_csv('/content/submission.csv', index=False)"
      ]
    }
  ]
}